---
pkg: "@nocobase/plugin-ai"
---
:::tip
เอกสารนี้แปลโดย AI หากมีข้อมูลที่ไม่ถูกต้อง โปรดดู[เวอร์ชันภาษาอังกฤษ](/en)
:::


# การสนทนาด้วยข้อความ (Text Chat)

## บทนำ

การใช้โหนด LLM ในเวิร์กโฟลว์ช่วยให้คุณสามารถเริ่มต้นการสนทนากับบริการ LLM ออนไลน์ได้ โดยใช้ประโยชน์จากความสามารถของโมเดลขนาดใหญ่เพื่อช่วยในการดำเนินงานตามกระบวนการทางธุรกิจต่างๆ ให้สำเร็จครับ/ค่ะ

![](https://static-docs.nocobase.com/202503041012091.png)

## การสร้างโหนด LLM

เนื่องจากการสนทนากับบริการ LLM มักใช้เวลานาน โหนด LLM จึงสามารถใช้ได้เฉพาะในเวิร์กโฟลว์แบบอะซิงโครนัสเท่านั้นครับ/ค่ะ

![](https://static-docs.nocobase.com/202503041013363.png)

## การเลือกโมเดล

อันดับแรก ให้เลือกบริการ LLM ที่เชื่อมต่อไว้แล้วครับ/ค่ะ หากยังไม่ได้เชื่อมต่อบริการ LLM คุณจะต้องเพิ่มการตั้งค่าบริการ LLM ก่อนครับ/ค่ะ ดูเพิ่มเติม: [การจัดการบริการ LLM](/ai-employees/quick-start/llm-service)

หลังจากเลือกบริการแล้ว แอปพลิเคชันจะพยายามดึงรายการโมเดลที่ใช้งานได้จากบริการ LLM เพื่อให้คุณเลือกครับ/ค่ะ บริการ LLM ออนไลน์บางแห่งอาจมี API สำหรับดึงโมเดลที่ไม่เป็นไปตามโปรโตคอล API มาตรฐาน ในกรณีเช่นนี้ ผู้ใช้สามารถป้อน Model ID ด้วยตนเองได้ครับ/ค่ะ

![](https://static-docs.nocobase.com/202503041013084.png)

## การตั้งค่าพารามิเตอร์การเรียกใช้

คุณสามารถปรับพารามิเตอร์สำหรับการเรียกใช้โมเดล LLM ได้ตามต้องการครับ/ค่ะ

![](https://static-docs.nocobase.com/202503041014778.png)

### Response format

สิ่งที่ควรทราบคือการตั้งค่า **Response format** ครับ/ค่ะ ตัวเลือกนี้ใช้เพื่อแจ้งให้โมเดลขนาดใหญ่ทราบถึงรูปแบบของผลลัพธ์ที่ต้องการ ซึ่งสามารถเป็นข้อความ (Text) หรือ JSON ก็ได้ครับ/ค่ะ หากคุณเลือกโหมด JSON โปรดทราบสิ่งต่อไปนี้ครับ/ค่ะ:

- โมเดล LLM ที่เกี่ยวข้องจะต้องรองรับการเรียกใช้ในโหมด JSON นอกจากนี้ ผู้ใช้จำเป็นต้องระบุอย่างชัดเจนใน Prompt ให้ LLM ตอบกลับในรูปแบบ JSON ตัวอย่างเช่น: "Tell me a joke about cats, respond in JSON with \`setup\` and \`punchline\` keys" มิฉะนั้น อาจไม่มีการตอบกลับ หรือเกิดข้อผิดพลาด `400 status code (no body)` ได้ครับ/ค่ะ
- ผลลัพธ์ที่ได้จะเป็นสตริง JSON ผู้ใช้จำเป็นต้องแยกวิเคราะห์ (parse) ด้วยความสามารถของโหนดเวิร์กโฟลว์อื่นๆ ก่อน จึงจะสามารถนำเนื้อหาที่มีโครงสร้างไปใช้งานได้ครับ/ค่ะ คุณยังสามารถใช้ฟังก์ชัน [Structured Output](/ai-employees/workflow/nodes/llm/structured-output) ได้ครับ/ค่ะ

## ข้อความ

อาร์เรย์ของข้อความที่ส่งไปยังโมเดล LLM สามารถรวมชุดข้อความประวัติได้ครับ/ค่ะ โดยข้อความรองรับสามประเภทดังนี้ครับ/ค่ะ:

- System - โดยทั่วไปใช้เพื่อกำหนดบทบาทและพฤติกรรมของโมเดล LLM ในการสนทนาครับ/ค่ะ
- User - เนื้อหาที่ผู้ใช้ป้อนครับ/ค่ะ
- Assistant - เนื้อหาที่โมเดลตอบกลับครับ/ค่ะ

สำหรับข้อความของผู้ใช้ หากโมเดลรองรับ คุณสามารถเพิ่มเนื้อหาหลายส่วนใน Prompt เดียวกันได้ ซึ่งจะตรงกับพารามิเตอร์ `content` ครับ/ค่ะ หากโมเดลที่คุณใช้รองรับเฉพาะพารามิเตอร์ `content` ในรูปแบบสตริงเท่านั้น (ซึ่งเป็นกรณีของโมเดลส่วนใหญ่ที่ไม่รองรับการสนทนาแบบหลายโมดอล) โปรดแยกข้อความเป็นหลาย Prompt โดยแต่ละ Prompt ให้มีเนื้อหาเพียงส่วนเดียวครับ/ค่ะ ด้วยวิธีนี้ โหนดจะส่งเนื้อหาเป็นสตริงครับ/ค่ะ

![](https://static-docs.nocobase.com/202503041016140.png)

คุณสามารถใช้ตัวแปรในเนื้อหาข้อความเพื่ออ้างอิงบริบทของเวิร์กโฟลว์ได้ครับ/ค่ะ

![](https://static-docs.nocobase.com/202503041017879.png)

## การใช้เนื้อหาการตอบกลับของโหนด LLM

คุณสามารถใช้เนื้อหาการตอบกลับของโหนด LLM เป็นตัวแปรในโหนดอื่นๆ ได้ครับ/ค่ะ

![](https://static-docs.nocobase.com/202503041018508.png)