---
pkg: "@nocobase/plugin-ai"
---
:::tip
यह दस्तावेज़ AI द्वारा अनुवादित किया गया है। किसी भी अशुद्धि के लिए, कृपया [अंग्रेजी संस्करण](/en) देखें
:::


# टेक्स्ट चैट

## परिचय

वर्कफ़्लो में LLM नोड का उपयोग करके, आप एक ऑनलाइन LLM सेवा के साथ बातचीत शुरू कर सकते हैं। यह बड़े मॉडल की क्षमताओं का लाभ उठाकर व्यावसायिक प्रक्रियाओं की एक श्रृंखला को पूरा करने में आपकी सहायता करता है।

![](https://static-docs.nocobase.com/202503041012091.png)

## LLM नोड बनाएँ

चूंकि LLM सेवाओं के साथ बातचीत में अक्सर समय लगता है, इसलिए LLM नोड का उपयोग केवल एसिंक्रोनस (asynchronous) वर्कफ़्लो में ही किया जा सकता है।

![](https://static-docs.nocobase.com/202503041013363.png)

## मॉडल चुनें

सबसे पहले, एक कनेक्टेड LLM सेवा चुनें। यदि अभी तक कोई LLM सेवा कनेक्टेड नहीं है, तो आपको पहले एक LLM सेवा कॉन्फ़िगरेशन जोड़ना होगा। संदर्भ: [LLM सेवा प्रबंधन](/ai-employees/quick-start/llm-service)

सेवा चुनने के बाद, एप्लिकेशन LLM सेवा से उपलब्ध मॉडल की सूची प्राप्त करने का प्रयास करेगा ताकि आप उनमें से चुन सकें। कुछ ऑनलाइन LLM सेवाओं में मॉडल प्राप्त करने के लिए ऐसे API हो सकते हैं जो मानक API प्रोटोकॉल के अनुरूप नहीं होते हैं; ऐसे मामलों में, उपयोगकर्ता मैन्युअल रूप से मॉडल ID भी दर्ज कर सकते हैं।

![](https://static-docs.nocobase.com/202503041013084.png)

## कॉल पैरामीटर सेट करें

आप आवश्यकतानुसार LLM मॉडल को कॉल करने के लिए पैरामीटर समायोजित कर सकते हैं।

![](https://static-docs.nocobase.com/202503041014778.png)

### रिस्पॉन्स फ़ॉर्मेट

यहां **रिस्पॉन्स फ़ॉर्मेट** सेटिंग पर ध्यान देना महत्वपूर्ण है। इस विकल्प का उपयोग बड़े मॉडल को उसके रिस्पॉन्स के फ़ॉर्मेट के लिए संकेत देने के लिए किया जाता है, जो टेक्स्ट या JSON हो सकता है। यदि आप JSON मोड चुनते हैं, तो निम्नलिखित बातों का ध्यान रखें:

- संबंधित LLM मॉडल को JSON मोड में कॉल किए जाने का समर्थन करना चाहिए। इसके अतिरिक्त, उपयोगकर्ता को प्रॉम्प्ट में LLM को JSON फ़ॉर्मेट में रिस्पॉन्स देने के लिए स्पष्ट रूप से संकेत देना होगा, उदाहरण के लिए: "Tell me a joke about cats, respond in JSON with \`setup\` and \`punchline\` keys"। अन्यथा, कोई रिस्पॉन्स नहीं मिल सकता है, जिसके परिणामस्वरूप `400 status code (no body)` त्रुटि हो सकती है।
- रिस्पॉन्स एक JSON स्ट्रिंग होगा। इसकी संरचित सामग्री का उपयोग करने के लिए उपयोगकर्ता को इसे अन्य वर्कफ़्लो नोड्स की क्षमताओं का उपयोग करके पार्स करना होगा। आप [संरचित आउटपुट](/ai-employees/workflow/nodes/llm/structured-output) सुविधा का भी उपयोग कर सकते हैं।

## संदेश

LLM मॉडल को भेजे गए संदेशों के ऐरे में ऐतिहासिक संदेशों का एक सेट शामिल हो सकता है। संदेश तीन प्रकारों का समर्थन करते हैं:

- सिस्टम - आमतौर पर बातचीत में LLM मॉडल की भूमिका और व्यवहार को परिभाषित करने के लिए उपयोग किया जाता है।
- उपयोगकर्ता - उपयोगकर्ता द्वारा दर्ज की गई सामग्री।
- असिस्टेंट - मॉडल द्वारा रिस्पॉन्स की गई सामग्री।

उपयोगकर्ता संदेशों के लिए, यदि मॉडल इसका समर्थन करता है, तो आप एक ही प्रॉम्प्ट में `content` पैरामीटर के अनुरूप कई सामग्री जोड़ सकते हैं। यदि आप जिस मॉडल का उपयोग कर रहे हैं वह केवल `content` पैरामीटर को एक स्ट्रिंग के रूप में समर्थन करता है (जो अधिकांश मॉडलों के लिए सच है जो मल्टी-मोडल बातचीत का समर्थन नहीं करते हैं), तो कृपया संदेश को कई प्रॉम्प्ट में विभाजित करें, जिसमें प्रत्येक प्रॉम्प्ट में केवल एक सामग्री हो। इस तरह, नोड सामग्री को एक स्ट्रिंग के रूप में भेजेगा।

![](https://static-docs.nocobase.com/202503041016140.png)

आप संदेश सामग्री में वर्कफ़्लो के संदर्भ को संदर्भित करने के लिए वेरिएबल्स का उपयोग कर सकते हैं।

![](https://static-docs.nocobase.com/202503041017879.png)

## LLM नोड की रिस्पॉन्स सामग्री का उपयोग करना

आप LLM नोड की रिस्पॉन्स सामग्री को अन्य नोड्स में एक वेरिएबल के रूप में उपयोग कर सकते हैं।

![](https://static-docs.nocobase.com/202503041018508.png)