:::tip
Ten dokument został przetłumaczony przez AI. W przypadku niedokładności, proszę odnieść się do [wersji angielskiej](/en)
:::

# Szybki start

## Wprowadzenie

Zanim zaczną Państwo korzystać z Pracownika AI, należy podłączyć usługę LLM online. NocoBase obecnie wspiera popularne usługi LLM online, takie jak OpenAI, Gemini, Claude, DepSeek, Qwen itp.
Oprócz usług LLM online, NocoBase obsługuje również podłączanie lokalnych modeli Ollama.

## Konfiguracja usługi LLM

Proszę przejść do strony konfiguracji wtyczki Pracownik AI, a następnie kliknąć zakładkę `LLM service`, aby przejść do strony zarządzania usługami LLM.

![20251021213122](https://static-docs.nocobase.com/20251021213122.png)

Proszę najechać kursorem na przycisk `Add New` w prawym górnym rogu listy usług LLM i wybrać usługę LLM, której chcą Państwo użyć.

![20251021213358](https://static-docs.nocobase.com/20251021213358.png)

Na przykładzie OpenAI, w wyskakującym okienku proszę wpisać łatwy do zapamiętania `title`, następnie wprowadzić `API key` uzyskany z OpenAI i kliknąć `Submit`, aby zapisać. W ten sposób zakończą Państwo konfigurację usługi LLM.

Pole `Base URL` zazwyczaj można pozostawić puste. Jeśli korzystają Państwo z zewnętrznej usługi LLM kompatybilnej z API OpenAI, proszę wypełnić odpowiednie pole `Base URL`.

![20251021214549](https://static-docs.nocobase.com/20251021214549.png)

## Test dostępności

Na stronie konfiguracji usługi LLM proszę kliknąć przycisk `Test flight`, wpisać nazwę modelu, którego chcą Państwo użyć, a następnie kliknąć przycisk `Run`, aby sprawdzić, czy usługa LLM i model są dostępne.

![20251021214903](https://static-docs.nocobase.com/20251021214903.png)