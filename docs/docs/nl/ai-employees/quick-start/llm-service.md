:::tip
Dit document is vertaald door AI. Voor onnauwkeurigheden, raadpleeg [de Engelse versie](/en)
:::

# Snel aan de slag

## Introductie

Voordat u de AI-medewerker kunt gebruiken, moet u eerst een online LLM-service koppelen. NocoBase ondersteunt momenteel de meest gangbare online LLM-services, zoals OpenAI, Gemini, Claude, DepSeek, Qwen, enz.
Naast online LLM-services biedt NocoBase ook ondersteuning voor het koppelen van lokale Ollama-modellen.

## LLM-service configureren

Ga naar de configuratiepagina van de AI-medewerker **plugin** en klik op het tabblad `LLM service` om de beheerpagina voor LLM-services te openen.

![20251021213122](https://static-docs.nocobase.com/20251021213122.png)

Beweeg de muisaanwijzer over de knop `Add New` rechtsboven in de lijst met LLM-services en selecteer de LLM-service die u wilt gebruiken.

![20251021213358](https://static-docs.nocobase.com/20251021213358.png)

Neem OpenAI als voorbeeld: voer in het pop-upvenster een gemakkelijk te onthouden `title` in, vul vervolgens de `API key` in die u van OpenAI hebt ontvangen en klik op `Submit` om op te slaan. Hiermee is de configuratie van de LLM-service voltooid.

De `Base URL` kunt u doorgaans leeg laten. Als u een externe LLM-service gebruikt die compatibel is met de OpenAI API, vul dan de bijbehorende Base URL in.

![20251021214549](https://static-docs.nocobase.com/20251021214549.png)

## Beschikbaarheid testen

Klik op de configuratiepagina van de LLM-service op de knop `Test flight`, voer de naam in van het model dat u wilt gebruiken en klik op de knop `Run` om te testen of de LLM-service en het model beschikbaar zijn.

![20251021214903](https://static-docs.nocobase.com/20251021214903.png)