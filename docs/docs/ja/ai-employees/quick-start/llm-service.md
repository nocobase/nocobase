:::tip
このドキュメントはAIによって翻訳されました。不正確な情報については、[英語版](/en)をご参照ください
:::

# クイックスタート

## はじめに

AI従業員を利用する前に、オンラインLLMサービスへの接続が必要です。NocoBaseは現在、OpenAI、Gemini、Claude、DepSeek、Qwenなどの主要なオンラインLLMサービスに対応しています。
オンラインLLMサービスに加えて、NocoBaseはOllamaローカルモデルの接続もサポートしています。

## LLMサービスの設定

AI従業員プラグインの設定ページに移動し、`LLM service` タブをクリックしてLLMサービス管理ページを開きます。

![20251021213122](https://static-docs.nocobase.com/20251021213122.png)

LLMサービスリストの右上にある`Add New`ボタンにマウスカーソルを合わせ、使用したいLLMサービスを選択します。

![20251021213358](https://static-docs.nocobase.com/20251021213358.png)

ここではOpenAIを例に説明します。ポップアップウィンドウで覚えやすい`title`を入力し、次にOpenAIで取得した`API key`を入力します。`Submit`をクリックして保存すると、LLMサービスの設定が完了します。

`Base URL`は通常、空欄のままで問題ありません。もしOpenAIインターフェースと互換性のあるサードパーティ製LLMサービスを使用している場合は、対応するBase URLを入力してください。

![20251021214549](https://static-docs.nocobase.com/20251021214549.png)

## 利用可能性テスト

LLMサービス設定ページで、`Test flight`ボタンをクリックし、使用したいモデル名を入力します。`Run`ボタンをクリックすると、LLMサービスとモデルが利用可能かテストできます。

![20251021214903](https://static-docs.nocobase.com/20251021214903.png)