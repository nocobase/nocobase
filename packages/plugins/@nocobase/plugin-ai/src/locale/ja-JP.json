{
  "AI integration": "AI統合",
  "LLM services": "LLMサービス",
  "LLM service": "LLMサービス",
  "Model": "モデル",
  "UID": "UID",
  "Provider": "LLMタイプ",
  "Messages": "メッセージ",
  "Structured output": "構造化出力",
  "Message": "メッセージ",
  "Role": "ロール",
  "Add content": "コンテンツを追加",
  "Add prompt": "プロンプトを追加",
  "Text": "テキスト",
  "Image": "画像",
  "Timout (ms)": "タイムアウト（ミリ秒）",
  "Max retries": "最大再試行回数",
  "Frequency penalty description": "-2.0から2.0の間の数値。正の値の場合、新しいトークンは既存テキストでの出現頻度に基づいて相応に処罰され、モデルが同じ内容を繰り返す可能性を減らします。",
  "Max completion tokens description": "リクエスト1回でのモデル生成completion の最大トークン数を制限します。入力トークンと出力トークンの総長は、モデルのコンテキスト長によって制限されます。",
  "Presence penalty description": "-2.0から2.0の間の数値。正の値の場合、新しいトークンは既存テキストにすでに出現しているかどうかに基づいて相応に処罰され、モデルが新しいトピックについて話す可能性を高めます。",
  "Response format description": "JSONモードを使用する場合、システムまたはユーザーメッセージを通じてモデルにJSON生成を指示する必要もあります。",
  "Temperature description": "サンプリング温度、0から2の間。0.8のような高い値は出力をよりランダムにし、0.2のような低い値はより集中的で確定的にします。",
  "Top P description": "サンプリング温度を調整する代替方法として、モデルはtop_p確率のトークンの結果を考慮します。つまり0.1は最高10%の確率に含まれるトークンのみが考慮されることを意味します。",
  "Get models list failed, you can enter a model name manually.": "モデルリストの取得に失敗しました。手動でモデル名を入力できます。"
}
