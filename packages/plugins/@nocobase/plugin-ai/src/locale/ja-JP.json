{
    "AI integration": "AI統合",
    "LLM services": "LLMサービス",
    "LLM service": "LLMサービス",
    "Model": "モデル",
    "Messages": "メッセージ",
    "Structured output": "構造化出力",
    "Message": "メッセージ",
    "Role": "ロール",
    "UID": "UID",
    "Add content": "コンテンツを追加",
    "Add prompt": "プロンプトを追加",
    "Provider": "プロバイダー",
    "Text": "テキスト",
    "Image": "画像",
    "Timout (ms)": "タイムアウト（ミリ秒）",
    "Max retries": "最大リトライ回数",
    "Frequency penalty description": "-2.0から2.0の間の数値。正の値は、テキスト内での既存の頻度に基づいて新しいトークンをペナルティし、モデルが同じ行をそのまま繰り返す可能性を減らします。",
    "Max completion tokens description": "完了のために生成できるトークン数の上限。表示される出力トークンと推論トークンを含みます。",
    "Presence penalty description": "-2.0から2.0の間の数値。正の値は、テキスト内に既に出現しているかどうかに基づいて新しいトークンをペナルティし、モデルが新しいトピックについて話す可能性を高めます。",
    "Response format description": "重要：JSONモードを使用する場合、システムまたはユーザーメッセージを介してモデルにJSONを生成するように指示する必要があります。",
    "Temperature description": "使用するサンプリング温度（0から2の間）。0.8のような高い値は出力をよりランダムにし、0.2のような低い値はより集中力があり決定論的な出力にします。",
    "Top P description": "温度によるサンプリングの代替となる核サンプリング。モデルはトップpの確率質量を持つトークンの結果を考慮します。0.1は確率質量の上位10%を占めるトークンのみが考慮されることを意味します。",
    "Get models list failed, you can enter a model name manually.": "モデルリストの取得に失敗しました。手動でモデル名を入力できます。"
  }