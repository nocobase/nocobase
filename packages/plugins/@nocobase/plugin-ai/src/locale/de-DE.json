{
  "AI integration": "KI-Integration",
  "LLM services": "LLM-Dienste",
  "LLM service": "LLM-Dienst",
  "Model": "Modell",
  "Messages": "Nachrichten",
  "Structured output": "Strukturierte Ausgabe",
  "Message": "Nachricht",
  "Role": "Rolle",
  "UID": "UID",
  "Add content": "Inhalt hinzufügen",
  "Add prompt": "Prompt hinzufügen",
  "Provider": "Anbieter",
  "Text": "Text",
  "Image": "Bild",
  "Timout (ms)": "Zeitüberschreitung (ms)",
  "Max retries": "Maximale Wiederholungen",
  "Frequency penalty description": "Zahl zwischen -2,0 und 2,0. Positive Werte bestrafen neue Tokens basierend auf ihrer vorhandenen Häufigkeit im bisherigen Text und verringern so die Wahrscheinlichkeit, dass das Modell dieselbe Zeile wörtlich wiederholt.",
  "Max completion tokens description": "Eine Obergrenze für die Anzahl der Tokens, die für eine Vervollständigung generiert werden können, einschließlich sichtbarer Ausgabe-Tokens und Reasoning-Tokens.",
  "Presence penalty description": "Zahl zwischen -2,0 und 2,0. Positive Werte bestrafen neue Tokens basierend darauf, ob sie bisher im Text vorkommen, und erhöhen die Wahrscheinlichkeit, dass das Modell über neue Themen spricht.",
  "Response format description": "Wichtig: Bei Verwendung des JSON-Modus müssen Sie das Modell auch selbst über eine System- oder Benutzernachricht anweisen, JSON zu erzeugen.",
  "Temperature description": "Welche Sampling-Temperatur verwendet werden soll, zwischen 0 und 2. Höhere Werte wie 0,8 machen die Ausgabe zufälliger, während niedrigere Werte wie 0,2 sie fokussierter und deterministischer machen.",
  "Top P description": "Eine Alternative zum Sampling mit Temperatur, genannt Nucleus-Sampling, bei dem das Modell die Ergebnisse der Tokens mit der Wahrscheinlichkeitsmasse top_p berücksichtigt. 0,1 bedeutet also, dass nur die Tokens berücksichtigt werden, die die obersten 10% der Wahrscheinlichkeitsmasse ausmachen.",
  "Get models list failed, you can enter a model name manually.": "Abrufen der Modellliste fehlgeschlagen, Sie können einen Modellnamen manuell eingeben."
}
